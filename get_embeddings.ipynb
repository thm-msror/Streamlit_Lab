{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8caec5",
   "metadata": {},
   "source": [
    "## Lab Activity: Hosting an App on Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57db3b",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Streamlit is a powerful framework for creating web applications with Python. \n",
    "\n",
    "This lab activity will, you will go through the process of hosting an Information Retrieval (IR) app using document embeddings on Streamlit. \n",
    "\n",
    "The app will allow users to enter a query and retrieve the top K most\n",
    "relevant documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce70fad",
   "metadata": {},
   "source": [
    "**Prerequisites**\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- Python installed (Python 3.7+ recommended)\n",
    "- pip installed for package management\n",
    "- Precomputed document embeddings stored as a NumPy array\n",
    "- A text-based dataset with corresponding documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5759aac",
   "metadata": {},
   "source": [
    "#### Step 1: Install Required Libraries\n",
    "\n",
    "To get started, install Streamlit and other necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beb5e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\tehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: gensim in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: streamlit in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.50.0)\n",
      "Requirement already satisfied: click in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.15.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (22.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\tehre\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.25.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\tehre\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart_open>=1.8.1->gensim) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim numpy scikit-learn streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7853b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a136de",
   "metadata": {},
   "source": [
    "#### Step 2: Download NLTK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d73e8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\tehre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tehre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tehre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1bec6",
   "metadata": {},
   "source": [
    "#### Step 3: Build Corpus for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f63f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 10788\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Prepare stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create documents\n",
    "# Original documents (for display in app)\n",
    "documents_original = []\n",
    "\n",
    "# Tokenized and cleaned documents (for embeddings)\n",
    "documents_processed = []\n",
    "\n",
    "for fileid in reuters.fileids():\n",
    "    raw_text = reuters.raw(fileid).strip()\n",
    "    documents_original.append(raw_text)  # Save original full text\n",
    "    \n",
    "    # Preprocess text: lowercase, remove stopwords & punctuation\n",
    "    words = [w.lower() for w in word_tokenize(raw_text) if w.isalnum() and w.lower() not in stop_words]\n",
    "    documents_processed.append(words)  # Keep as list of words for Word2Vec\n",
    "    \n",
    "print(\"Total documents:\", len(documents_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c315a5a",
   "metadata": {},
   "source": [
    "#### Step 4: Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16b558c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10407\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=documents_processed,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"Vocabulary size:\", len(model.wv.index_to_key))\n",
    "\n",
    "# Save the Word2Vec model for Streamlit app\n",
    "model.save(\"word2vec_reuters.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9818ee5",
   "metadata": {},
   "source": [
    "#### Step 5: Create Document Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01105e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (10788, 100)\n"
     ]
    }
   ],
   "source": [
    "doc_embeddings = []\n",
    "\n",
    "for tokens in documents_processed:\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if vectors:\n",
    "        doc_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        doc_vector = np.zeros(model.vector_size)\n",
    "    doc_embeddings.append(doc_vector)\n",
    "\n",
    "doc_embeddings = np.array(doc_embeddings)\n",
    "print(\"Embeddings shape:\", doc_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d8429",
   "metadata": {},
   "source": [
    "#### Step 6: Save Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2263e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings, documents, and Word2Vec model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "np.save(\"embeddings.npy\", doc_embeddings)\n",
    "\n",
    "with open(\"documents_original.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc in documents_original:\n",
    "        f.write(doc + \"\\n\")\n",
    "\n",
    "print(\"Embeddings, documents, and Word2Vec model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27630a",
   "metadata": {},
   "source": [
    "**Summary of variables for app**\n",
    "\n",
    "- documents_original -> list of full text documents for display\n",
    "- doc_embeddings     -> NumPy array of embeddings aligned with documents_original\n",
    "- model              -> Word2Vec model used for query embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
